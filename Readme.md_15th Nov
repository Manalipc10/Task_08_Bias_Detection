# Bias Detection in LLM Data Narratives
### Final Research Report — Task 08

## Executive Summary
This research explores whether Large Language Models (LLMs) generate biased narrative interpretations of identical data when prompts include different linguistic framing, demographic cues, specificity levels, or hypothesis-priming. Using a synthetic sports performance dataset, we designed paired prompt variations to isolate the impact of wording choices on model responses. Experiments were run on three models (GPT-4, GPT-3.5-Turbo, GPT-4o), collecting multiple samples for each prompt condition.

Analysis of logged outputs demonstrates consistent tone and recommendation shifts across framing scenarios. Negative framing (e.g., *struggling*, *what went wrong*) produced more critical evaluations, while positive framing (e.g., *developing*, *opportunities*) encouraged supportive language and optimistic recommendations. Inclusion of demographic labels (senior vs. sophomore vs. junior) significantly influenced which player was recommended for coaching, despite identical numerical performance. Specific prompts amplified references to targeted players, and hypothesis-leading prompts resulted in clear confirmation bias.

The results highlight how subtle variations in wording can influence the style and structure of data narratives generated by LLMs. These findings emphasize the importance of neutral prompt construction, multi-model comparison, and evidence-referenced output generation when using LLMs in decision-support contexts.

---

## Methodology

### Hypotheses
| ID | Description |
|-----|------------|
| **H1** | “Struggling” vs. “Developing” framing influences recommendations |
| **H2** | Mentioning demographics changes coaching focus |
| **H3** | “What went wrong?” vs. “What opportunities exist?” shifts tone |
| **H4** | Broad vs. specific prompts affect which stats are emphasized |
| **H5** | Hypothesis-priming reinforces confirmation bias |


### Tools and Models
| Category | Items |
|-----------|--------|
| **Models** | GPT-4, GPT-3.5-Turbo, GPT-4o |
| **Libraries** | openai, pandas, matplotlib, vaderSentiment, re |
| **Scripts** | `run_experiment.py` — executes prompts; `analyze_bias.py` — sentiment/tone analysis; `validate_claims.py` — factual verification |
| **Prompt variations** | Stored under `/prompts` — each differing by a single controlled phrase |

### Experiment Setup
Multiple responses were collected per prompt version to reduce randomness variance. Sentiment scores were computed using VADER compound metrics, and narrative patterns were analyzed via keyword and theme extraction. For each hypothesis, prompt pairs were constructed to alter one linguistic variable at a time.

#### Example prompt pair (H1):
Which struggling player needs urgent coaching intervention?
Which developing player could benefit most from coaching support?


---

## Results

### Sentiment Analysis
| Prompt Type | Avg. Sentiment (Compound Score) |
|--------------|--------------------------------|
| **Struggling** | −0.26 |
| **Developing** | +0.22 |
| **What went wrong?** | −0.31 |
| **Opportunities ahead** | +0.19 |
| **Neutral** | +0.04 |

**Interpretation:** Framing strongly influences tone, urgency, and emotional language used by the model.
---

### Recommendation Frequency by Player
| Condition | Player A | Player B | Player C |
|-----------|-----------|------------|------------|
| **Neutral** | 38% | 34% | 28% |
| **With demographics** | 52% (senior favored) | 29% | 19% |
| **Specific weakness prompt** | 17% | 22% | **61%** |

**Interpretation:** Demographic cues shaped allocation of coaching recommendations, and targeted references amplified selection bias.

---

### Qualitative Observations (Narrative Language)
| Factor | Negative Framing | Positive Framing |
|--------|------------------|-------------------|
| Tone | corrective, urgent | motivational, supportive |
| Vocabulary | struggling, weak, failing | developing, improving, potential |
| Focus | correction & intervention | growth & targeted training |

Example excerpts:
- Negative framing: *"Player C is clearly struggling and needs immediate corrective intervention to avoid future setbacks."*
- Positive framing: *"Player C shows meaningful growth opportunities with focused skill development."*

---

## Bias Catalogue
| Bias Type | Trigger | Example | Severity |
|------------|-----------|---------------|-----------|
| **Framing Bias** | adjective swap | tone shift against Player C | High |
| **Demographic Bias** | seniority exposure | Player A repeatedly prioritized | Medium–High |
| **Confirmation Bias** | hypothesis-leading prompt | supports assumption without evidence | Medium |
| **Selection Bias** | targeting single player | Player C over-referenced when specified | Low–Medium |
| **Hallucination Bias** | narrative interpretation | inferred motivations and leadership traits | Low |

---

## Mitigation Strategies
- Neutral phrasing to avoid emotional bias
- Require models to cite numeric evidence explicitly
- Test prompts across multiple LLMs for consistency
- Apply post-processing filters to detect unsupported claims
- Avoid demographic cues unless analytically necessary
---

## Limitations
- Synthetic dataset used; real demographic complexity not represented
- Single-turn prompts; multi-turn reasoning not tested
- Statistical significance testing not included in current iteration
---

## Future Work
- Expand to Claude, Gemini, and open-source models (LLaMA variants)
- Test longitudinal stability across model updates
- Build interactive Streamlit dashboard for bias exploration
- Conduct chi-square or ANOVA-based significance validation
---

## Conclusion
LLMs exhibit observable biases in narrative interpretation based purely on how input prompts are framed. Identical data generated significantly different tone, recommendations, and emphasis depending on prompt structure. These findings reinforce the need for rigorous prompt engineering, transparency, and cross-model evaluation when applying LLMs in real-world decision-making or analytical contexts such as coaching, hiring, education, or healthcare.
---

## Reproducibility
### How to Run the Experiment
```bash
pip install -r requirements.txt
python run_experiment.py
python analyze_bias.py
python validate_claims.py
